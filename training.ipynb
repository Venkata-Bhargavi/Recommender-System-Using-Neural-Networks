{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87dd1934-32d3-4fb7-b25f-f2851dfa3d02",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ec14e4-40a0-4eed-b528-0c16b8fbd020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import sklearn\n",
    "import random\n",
    "import zipfile\n",
    "import torch\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from zipfile import ZipFile\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a167f9c8-1949-4881-a43d-6e9bfc38d05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 25 14:21:11 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-12GB           Off | 00000000:04:00.0 Off |                    0 |\n",
      "| N/A   37C    P0              29W / 250W |      0MiB / 12288MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65a71f83-646e-455a-beab-b45279fb7af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieUserRatingDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 rated_users: pd.DataFrame,\n",
    "                 total_samples: pd.DataFrame,\n",
    "                 unrated_user_ratio: int\n",
    "                 ) -> None:\n",
    "        super(MovieUserRatingDataset, self).__init__()\n",
    "\n",
    "        self.rated_users = rated_users\n",
    "        self.total_samples = total_samples\n",
    "        self.unrated_user_ratio = unrated_user_ratio\n",
    "\n",
    "        self.users, self.items, self.ratings = self.unrated_user_sampling()\n",
    "\n",
    "    \n",
    "    def unrated_user_sampling(self):\n",
    "        rated_users = self.rated_users\n",
    "        total_samples = self.total_samples\n",
    "        users_list, items_list, labels_list = [], [], []\n",
    "        user_item_set = set(zip(rated_users['userId'], rated_users['movieId']))\n",
    "        total_user_item_set = set(zip(total_samples['userId'], total_samples['movieId']))\n",
    "        all_movie_ids = total_samples['movieId'].unique()\n",
    "        unrated_user_ratio = self.unrated_user_ratio\n",
    "\n",
    "        for user, item in user_item_set:\n",
    "            # Add positive instance\n",
    "            users_list.append(user)\n",
    "            items_list.append(item)\n",
    "            labels_list.append(1.0)\n",
    "\n",
    "            # Initialize visited items\n",
    "            rated = [item]\n",
    "\n",
    "            # Add negative instances\n",
    "            for _ in range(unrated_user_ratio):\n",
    "                # Randomly select a negative item\n",
    "                negative_item = np.random.choice(all_movie_ids)\n",
    "\n",
    "                # Ensure the negative item is not in the total dataset and has not been visited\n",
    "                while (user, negative_item) in total_user_item_set or negative_item in rated:\n",
    "                    negative_item = np.random.choice(all_movie_ids)\n",
    "\n",
    "                users_list.append(user)\n",
    "                items_list.append(negative_item)\n",
    "                rated.append(negative_item)\n",
    "                labels_list.append(0.0)\n",
    "\n",
    "        print(f\"Not rated user sampled data size: {len(labels_list)}\")\n",
    "        return torch.tensor(users_list), torch.tensor(items_list), torch.tensor(labels_list)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.users)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.users[index], self.items[index], self.ratings[index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce294415-b17a-4eba-bfbf-de0b68369835",
   "metadata": {},
   "source": [
    "## Multi Layer Perceptron (A Custom Model for Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae96a70-750f-45ce-af30-ab5f80aa329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModelLoader(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PretrainedModelLoader, self).__init__()\n",
    "\n",
    "    def load_pretrained_model(self, model, pretrained_model):\n",
    "        model.user_embedding.weight.data.copy_(pretrained_model.user_embedding.weight)\n",
    "        model.movie_item_embedding.weight.data.copy_(pretrained_model.movie_item_embedding.weight)\n",
    "        for layer, pretrained_layer in zip(model.multilayer_model, pretrained_model.multilayer_model):\n",
    "            if isinstance(layer, nn.Linear) and isinstance(pretrained_layer, nn.Linear):\n",
    "                layer.weight.data.copy_(pretrained_layer.weight)\n",
    "                layer.bias.data.copy_(pretrained_layer.bias)\n",
    "\n",
    "class UserRatingsMultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self,num_users:int,num_items:int,num_factor:int=8,total_hidden_layers=None,use_pretrained: bool = False,NeuralMF:bool = False,pretrained_model=None\n",
    "                 ):\n",
    "        super(UserRatingsMultiLayerPerceptron, self).__init__()\n",
    "\n",
    "        if total_hidden_layers is None:\n",
    "            total_hidden_layers = [128,64,32,16,8]\n",
    "\n",
    "        self.pretrained_model = pretrained_model\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.use_pretrained = use_pretrained\n",
    "        self.user_embedding = nn.Embedding(num_users, total_hidden_layers[0] // 2)\n",
    "        self.movie_item_embedding = nn.Embedding(num_items, total_hidden_layers[0] // 2)\n",
    "        self.NeuralMF = NeuralMF\n",
    "        multiple_hidden_layers = []\n",
    "\n",
    "        for idx, layer_size in enumerate(total_hidden_layers):\n",
    "            # Add layers to the MLP model\n",
    "            multiple_hidden_layers.append(nn.Linear(layer_size, layer_size // 2))\n",
    "            multiple_hidden_layers.append(nn.ReLU())\n",
    "\n",
    "        # stack the layers\n",
    "        self.multilayer_model = nn.Sequential(*multiple_hidden_layers)\n",
    "\n",
    "        # initialize prediction layer\n",
    "        self.predict_layer = nn.Linear(total_hidden_layers[-1] // 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        if self.use_pretrained:\n",
    "            PretrainedModelLoader().load_pretrained_model(self, self.pretrained_model)\n",
    "        else:\n",
    "            self._init_weights()\n",
    "            \n",
    "    # Initialize weights\n",
    "    def _init_weights(self):\n",
    "        if not self.use_pretrained:\n",
    "            nn.init.normal_(self.user_embedding.weight, std=1e-2)\n",
    "            nn.init.normal_(self.movie_item_embedding.weight, std=1e-2)\n",
    "            for layer in self.multilayer_model:\n",
    "                if isinstance(layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(layer.weight)\n",
    "        if not self.NeuralMF:\n",
    "            nn.init.normal_(self.predict_layer.weight, std=1e-2)\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        '''\n",
    "        function for forward propogation to generate aggregated signal\n",
    "        '''\n",
    "        # Convert user tensor to LongTensor\n",
    "        user = user.long()\n",
    "        item = item.long()\n",
    "\n",
    "        # Embeding movie and user\n",
    "        embedding_user = self.user_embedding(user)\n",
    "        embedding_item = self.movie_item_embedding(item)\n",
    "\n",
    "        # combining (concatenating) users and movie(item embeddings)\n",
    "        concatinating_embed_input = torch.cat((embedding_user, embedding_item), dim=-1)\n",
    "\n",
    "        # Forward pass through MLP layers\n",
    "        aggregated_signal = self.multilayer_model(concatinating_embed_input)\n",
    "\n",
    "        if not self.NeuralMF:\n",
    "            # Forward Propogation with sigmoid activation function for classification\n",
    "            aggregated_signal = self.predict_layer(aggregated_signal)\n",
    "            aggregated_signal = self.sigmoid(aggregated_signal)\n",
    "            aggregated_signal = aggregated_signal.view(-1)\n",
    "\n",
    "        return aggregated_signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133d6cd9-1be6-462e-8c61-f89e0a387c03",
   "metadata": {},
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79bbfc27-cbb4-4626-b1ec-1da7166d255c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def compute_hit_rate(gt_item, pred_items):\n",
    "\n",
    "    if gt_item in pred_items:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def compute_ndcg(gt_item, pred_items):\n",
    "\n",
    "    if gt_item in pred_items:\n",
    "        index = pred_items.index(gt_item)\n",
    "        return np.reciprocal(np.log2(index+2))\n",
    "    return 0\n",
    "\n",
    "def compute_metrics(model, test_loader, top_k, device):\n",
    "\n",
    "    hit_rate, ndcg_score = [], []\n",
    "\n",
    "    for user, item, label in test_loader:\n",
    "        \n",
    "        user = user.to(device) #moving user or item to device(CPU or GPU)\n",
    "        item = item.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        predictions = model(user, item)\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "\n",
    "        # Get recommended items\n",
    "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "\n",
    "        # Computing hit rate and cumulative gain (NDCG) for each user\n",
    "        gt_item = item[0].item()\n",
    "        hit_rate.append(compute_hit_rate(gt_item, recommends))\n",
    "        ndcg_score.append(compute_ndcg(gt_item, recommends))\n",
    "\n",
    "    # Compute mean HR and NDCG\n",
    "    hit_rate_mean = np.mean(hit_rate)\n",
    "    mean_ndcg = np.mean(ndcg_score)\n",
    "\n",
    "    return hit_rate_mean, mean_ndcg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2ef9d8-1e45-4780-a38c-22ec10ebd186",
   "metadata": {},
   "source": [
    "## Training-Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23d59e2-c9ec-4ee0-aaae-f9cf0033a2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class MLP_Trainer():\n",
    "    def __init__(self, model, optimizer, epochs, dataloader, criterion, test_obj, device='cuda', print_cost=True):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.dataloader = dataloader\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.print_cost = print_cost\n",
    "        self.test_obj = test_obj\n",
    "\n",
    "    def train(self):\n",
    "        model = self.model\n",
    "        optimizer = self.optimizer\n",
    "        total_epochs = self.epochs\n",
    "        dataloader = self.dataloader\n",
    "        criterion = self.criterion\n",
    "        total_batch = len(dataloader)\n",
    "        device = self.device\n",
    "        test_obj = self.test_obj\n",
    "\n",
    "        losses_list = []\n",
    "        #iterating over epochs\n",
    "        for epoch in range(total_epochs):\n",
    "            for user, item, target in dataloader:\n",
    "                user, item, target = user.to(device), item.to(device), target.float().to(device)\n",
    "                optimizer.zero_grad()\n",
    "                pred = model(user, item)\n",
    "                loss = criterion(pred, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            if self.print_cost:\n",
    "                hit_rate, NDCG_score = compute_metrics(model, test_obj, 10, device)\n",
    "                print(\"Epoch: {} Hit_Rate: {:.3f}\\tNDCG: {:.3f}\".format(epoch, np.mean(hit_rate), np.mean(NDCG_score)))\n",
    "\n",
    "            losses_list.append(loss.item())\n",
    "\n",
    "        if self.print_cost:\n",
    "            print('--------------Training Completed-----------')\n",
    "        #returning list of training losses\n",
    "        return losses_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce693d2-c5c3-40a6-b40e-ba8804ec517e",
   "metadata": {},
   "source": [
    "## Checking GPU/CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec99e7b4-9fd0-447e-9d70-d2d81be61f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "CUDA device: 0\n",
      "No of GPUs in use 1\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Print GPU information\n",
    "if torch.cuda.is_available():\n",
    "    print('CUDA device:', torch.cuda.current_device())\n",
    "    print('No of GPUs in use', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94030a20-2d4c-4f0b-b611-bd214976100f",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "464d971c-18da-42d4-ac3c-2cbb87b5c5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to save checkpoints (model)\n",
    "pretrain_dir = 'models_trained'\n",
    "if not os.path.isdir(pretrain_dir):\n",
    "    os.makedirs(pretrain_dir)\n",
    "\n",
    "# Load train, test, and total datasets\n",
    "train_dataframe = pd.read_csv(\"/home/sikhakolli.v/rec/data/interim/train.csv\")\n",
    "total_dataframe = pd.read_csv(\"/home/sikhakolli.v/rec/data/interim/entire_dataset.csv\")\n",
    "test_dataframe = pd.read_csv(\"/home/sikhakolli.v/rec/data/interim/evaluation.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de16140-7c9a-40fe-84b8-83079fb0613a",
   "metadata": {},
   "source": [
    "## DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47c10703-987e-4a67-81e6-e6a070e6c0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not rated user sampled data size: 501130\n",
      "Not rated user sampled data size: 61000\n",
      "<class '__main__.MovieUserRatingDataset'>:<__main__.MovieUserRatingDataset object at 0x2afb618bfdf0>\n",
      "Data loaded successfully!\n",
      "UserRatingsMultiLayerPerceptron(\n",
      "  (user_embedding): Embedding(611, 64)\n",
      "  (movie_item_embedding): Embedding(193610, 64)\n",
      "  (multilayer_model): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=16, out_features=8, bias=True)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=8, out_features=4, bias=True)\n",
      "    (9): ReLU()\n",
      "  )\n",
      "  (predict_layer): Linear(in_features=4, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create MovieLens datasets\n",
    "train_set = MovieUserRatingDataset(rated_users=train_dataframe, total_samples=total_dataframe, unrated_user_ratio=4)\n",
    "test_set = MovieUserRatingDataset(rated_users=test_dataframe, total_samples=total_dataframe, unrated_user_ratio=99)\n",
    "\n",
    "print(f\"{type(train_set)}:{train_set}\")\n",
    "# Get number of unique users and movies\n",
    "max_num_users, max_num_items = total_dataframe['userId'].max() + 1, total_dataframe['movieId'].max() + 1\n",
    "print('Data loaded successfully!')\n",
    "\n",
    "# Data Loaders for effecient loading\n",
    "dataloader_train = DataLoader(dataset=train_set, batch_size=32, shuffle=True, num_workers=0)\n",
    "dataloader_test = DataLoader(dataset=test_set, batch_size=100, shuffle=False, num_workers=0, drop_last=True)\n",
    "\n",
    "# Initializing model\n",
    "model = UserRatingsMultiLayerPerceptron(num_users=max_num_users, num_items=max_num_items, NeuralMF=False)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "model.to(device)\n",
    "\n",
    "#Using Binary cross entropy loss\n",
    "criterion = torch.nn.BCELoss()\n",
    "save_model = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f727f0db-982e-492a-8d2b-65cfd3f02d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: (tensor(89), tensor(3604), tensor(1.))\n",
      "Sample 2: (tensor(89), tensor(1621), tensor(0.))\n",
      "Sample 3: (tensor(89), tensor(6058), tensor(0.))\n",
      "Sample 4: (tensor(89), tensor(45), tensor(0.))\n",
      "Sample 5: (tensor(89), tensor(4433), tensor(0.))\n"
     ]
    }
   ],
   "source": [
    "#visualizing tensors\n",
    "for i in range(5):  # Printing first 5 samples\n",
    "    sample = train_set[i]\n",
    "    print(f\"Sample {i+1}: {sample}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45178b23-da69-47ef-8dca-3a6418e093b7",
   "metadata": {},
   "source": [
    "## Initializing Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db51835-7155-413c-afb4-f02b029b955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined Trainer Class\n",
      "starting to train\n",
      "Epoch [1/10], Loss: 0.3549\n",
      "Epoch [2/10], Loss: 0.3181\n",
      "Epoch [3/10], Loss: 0.2794\n",
      "Epoch [4/10], Loss: 0.2523\n",
      "Epoch [5/10], Loss: 0.2342\n",
      "Epoch [6/10], Loss: 0.2180\n",
      "Epoch [7/10], Loss: 0.2037\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Define the training class\n",
    "class Trainer:\n",
    "    def __init__(self, model, optimizer, criterion, epochs, train_loader, test_loader, device='cuda', print_cost=True):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.epochs = epochs\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.print_cost = print_cost\n",
    "\n",
    "    def train(self):\n",
    "        self.model.to(self.device)\n",
    "        self.model.train()\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            running_loss = 0.0\n",
    "            for user, item, target in self.train_loader:\n",
    "                user, item, target = user.to(self.device), item.to(self.device), target.float().to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                outputs = self.model(user, item)\n",
    "                loss = self.criterion(outputs, target)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                running_loss += loss.item()\n",
    "\n",
    "            if self.print_cost:\n",
    "                print(f'Epoch [{epoch + 1}/{self.epochs}], Loss: {running_loss / len(self.train_loader):.4f}')\n",
    "\n",
    "    def model_evaluate(self, top_k=10):\n",
    "        self.model.eval()\n",
    "        HR, NDCG = [], []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for user, item, _ in self.test_loader:\n",
    "                user, item = user.to(self.device), item.to(self.device)\n",
    "\n",
    "                predictions = self.model(user, item)\n",
    "                _, indices = torch.topk(predictions, top_k)\n",
    "\n",
    "                recommended_items = torch.take(item, indices).cpu().numpy().tolist()\n",
    "                gt_item = item[0].item()\n",
    "\n",
    "                HR.append(compute_hit_rate(gt_item, recommended_items))\n",
    "                NDCG.append(compute_ndcg(gt_item, recommended_items))\n",
    "\n",
    "        return np.mean(HR), np.mean(NDCG)\n",
    "\n",
    "print(\"Defined Trainer Class\")\n",
    "# Define the training parameters\n",
    "model = UserRatingsMultiLayerPerceptron(num_users=max_num_users, num_items=max_num_items, NeuralMF=False)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = torch.nn.BCELoss()\n",
    "epochs = 10\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print_cost = True\n",
    "\n",
    "# Create and initialize the Trainer object\n",
    "trainer = Trainer(model=model,\n",
    "                  optimizer=optimizer,\n",
    "                  criterion=criterion,\n",
    "                  epochs=epochs,\n",
    "                  train_loader=dataloader_train,\n",
    "                  test_loader=dataloader_test,\n",
    "                  device=device,\n",
    "                  print_cost=print_cost)\n",
    "\n",
    "print(\"starting to train\")\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "print(f'Training time: {end_time - start_time:.5f} seconds')\n",
    "\n",
    "# Save the model if required\n",
    "if save_model:\n",
    "    pretrain_model_dir = os.path.join(pretrain_dir, \"MLP.pth\")\n",
    "    torch.save(model, pretrain_model_dir)\n",
    "\n",
    "# testing the trained model with test data and getting top 10 results\n",
    "HR, NDCG = trainer.model_evaluate(top_k=10)\n",
    "print(f'HR: {np.mean(HR):.3f}, NDCG: {np.mean(NDCG):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a94a397-82fe-44bf-b843-380e91468886",
   "metadata": {},
   "source": [
    "## Inferring the trained model with adhoc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45942a9f-9a1b-4d8a-b852-fac8fadd0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_for_single_user(model, user_id, top_k, total_dataframe, test_loader, device):\n",
    "    for user, item, label in test_loader:\n",
    "        if user[0] == user_id:\n",
    "            #moving data to GPU if available\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "\n",
    "            print(f\"Given User {user_id} is found in the test dataset.\")\n",
    "            predictions = model(user, item)\n",
    "            _, indices = torch.topk(predictions, top_k)\n",
    "\n",
    "            recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "\n",
    "            #extract titles of the movie recommendations\n",
    "            recommended_titles = [total_dataframe[total_dataframe['movieId'] == rec]['title'].values[0] for rec in recommends]\n",
    "\n",
    "            return {'user': user.item() if user.numel() == 1 else user.tolist(),\n",
    "                    'movie_recommendations': recommended_titles}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261e083a-fa7a-47b2-9bd3-8e71ecdf7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id_to_infer = 453 \n",
    "recommendations = get_rec_for_single_user(model, user_id_to_infer, top_k=10, total_dataframe=total_dataframe, test_loader=dataloader_test, device=device)\n",
    "print(f\"User: {recommendations['user'][0]}, Recommendations: {recommendations['movie_recommendations']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83c4cf9-87fc-4931-92dc-3f0270880176",
   "metadata": {},
   "source": [
    "## Recommendation with score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b5d7d-02a4-4ab3-8a41-d8b958bee3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendation_score(model, test_loader, top_k, total_dataframe, device):\n",
    "\n",
    "    HR, NDCG, rec_movies = [], [], []\n",
    "\n",
    "    for user, item, label in test_loader:\n",
    "        user = user.to(device)\n",
    "        item = item.to(device)\n",
    "\n",
    "        predictions = model(user, item)\n",
    "        _, indices = torch.topk(predictions, top_k)\n",
    "\n",
    "        recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "\n",
    "        gt_item = item[0].item()\n",
    "        HR.append(compute_hit_rate(gt_item, recommends))\n",
    "        NDCG.append(compute_ndcg(gt_item, recommends))\n",
    "\n",
    "        # Get movie titles for the recommended movies\n",
    "        recommended_titles = [total_dataframe[total_dataframe['movieId'] == rec]['title'].values[0] for rec in recommends]\n",
    "\n",
    "        rec_movies.append({\n",
    "            'user': user.item() if user.numel() == 1 else user.tolist(),\n",
    "            'ground_truth': total_dataframe[total_dataframe['movieId'] == gt_item]['title'].values[0],\n",
    "            'recommendations': recommended_titles\n",
    "        })\n",
    "\n",
    "    return np.mean(HR), np.mean(NDCG), rec_movies\n",
    "\n",
    "HR, NDCG, rec_movies = get_recommendation_score(model, test_loader=dataloader_test, top_k=10, total_dataframe=total_dataframe, device=device)\n",
    "\n",
    "print(\"Hit Rate:\", HR)\n",
    "print(\"NDCG_score:\", NDCG)\n",
    "\n",
    "# Print individual recommendations with movie titles\n",
    "for rec in rec_movies:\n",
    "    print(f\"User: {rec['user'][0]}, Recommendations: {rec['recommendations']}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebb6f76-ae5b-41c1-9f67-d2241624dbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a7e47-c521-4d10-9f2f-19cea092dc36",
   "metadata": {},
   "source": [
    "## Re-Ranking Recommendations to Get Best Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a2c6e3-ff20-4c29-ab20-0042883cf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rec_for_single_user(model, user_id, top_k, total_dataframe, test_loader, device):\n",
    "    ground_truth = []  # Ground truth items for the user\n",
    "    recommended_items = []  # Recommended items for the user\n",
    "\n",
    "    for user, item, label in test_loader:\n",
    "        if user[0] == user_id:\n",
    "            # Move data to GPU if available\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            \n",
    "            print(f\"Given User {user_id} is found in the test dataset.\")\n",
    "            predictions = model(user, item)\n",
    "            _, indices = torch.topk(predictions, top_k)\n",
    "            \n",
    "            recommends = torch.take(item, indices).cpu().numpy().tolist()\n",
    "            \n",
    "            # Calculate popularity score for each recommended movie\n",
    "            popularity_scores = [total_dataframe[total_dataframe['movieId'] == rec].shape[0] for rec in recommends]\n",
    "            \n",
    "            # Sort recommendations based on popularity score\n",
    "            sorted_indices = np.argsort(popularity_scores)[::-1]  # Sort in descending order\n",
    "            re_ranked_recommendations = [recommends[i] for i in sorted_indices]\n",
    "            re_ranked_scores = [popularity_scores[i] for i in sorted_indices]\n",
    "            \n",
    "            # Extract titles of the re-ranked movie recommendations\n",
    "            re_ranked_titles = [total_dataframe[total_dataframe['movieId'] == rec]['title'].values[0] for rec in re_ranked_recommendations]\n",
    "            \n",
    "            ground_truth.append(item[0].item())  # Ground truth item for this user\n",
    "            recommended_items.append(re_ranked_recommendations)  # Recommended items for this user\n",
    "            \n",
    "            return {'user': user.item() if user.numel() == 1 else user.tolist(),\n",
    "                    'movie_recommendations': re_ranked_titles,\n",
    "                    'scores': re_ranked_scores,\n",
    "                    'ground_truth': ground_truth,\n",
    "                    'recommended_items': recommended_items}\n",
    "\n",
    "        \n",
    "def compute_reranked_metrics(ground_truth, recommended_items, top_k):\n",
    "    hr = np.zeros(len(ground_truth))\n",
    "    ndcg = np.zeros(len(ground_truth))\n",
    "\n",
    "    for i in range(len(ground_truth)):\n",
    "        gt_item = ground_truth[i]\n",
    "        rec_items = recommended_items[i]\n",
    "\n",
    "        if gt_item in rec_items:\n",
    "            hr[i] = 1\n",
    "\n",
    "            index = rec_items.index(gt_item)\n",
    "            ndcg[i] = 1 / np.log2(index + 2)\n",
    "\n",
    "    return np.mean(hr), np.mean(ndcg)\n",
    "\n",
    "# Example usage\n",
    "user_id_to_infer = 453 \n",
    "recommendations = get_rec_for_single_user(model, user_id_to_infer, top_k=10, total_dataframe=total_dataframe, test_loader=dataloader_test, device=device)\n",
    "print(f\"User: {recommendations['user']}, Recommendations: {recommendations['movie_recommendations']}, Score: {recommendations['scores']}\")\n",
    "\n",
    "# Calculate HR and NDCG\n",
    "hr_score, ndcg_score = compute_reranked_metrics(recommendations['ground_truth'], recommendations['recommended_items'], top_k=10)\n",
    "print(\"Hit Rate:\", hr_score)\n",
    "print(\"NDCG Score:\", ndcg_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe9702-39db-4ca6-b9ca-a85a03b2fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "user_id_to_infer = 572\n",
    "recommendations = get_rec_for_single_user(model, user_id_to_infer, top_k=10, total_dataframe=total_dataframe, test_loader=dataloader_test, device=device)\n",
    "print(f\"User: {recommendations['user']}, Recommendations: {recommendations['movie_recommendations']}, Score: {recommendations['scores']}\")\n",
    "\n",
    "# Calculate HR and NDCG\n",
    "hr_score, ndcg_score = compute_reranked_metrics(recommendations['ground_truth'], recommendations['recommended_items'], top_k=10)\n",
    "print(\"Hit Rate:\", hr_score)\n",
    "print(\"NDCG Score:\", ndcg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacdd78f-4d9e-48f5-8ecf-207c902ca7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
